- title: "A Neural Network Architecture for Learning Word-Referent Associations in Multiple Contexts"
  year: 2019
  image: CSWL.png
  abstract: "This article proposes a biologically inspired neurocomputational architecture which learns associations between words and referents in different contexts, considering evidence collected from the literature of Psycholinguistics and Neurolinguistics. The multi-layered architecture takes as input raw images of objects (referents) and streams of word’s phonemes (labels), builds an adequate representation, recognizes the current context, and associates label with referents incrementally, by employing a Self-Organizing Map which creates new association nodes (prototypes) as required, adjusts the existing prototypes to better represent the input stimuli and removes prototypes that become obsolete/unused. The model takes into account the current context to retrieve the correct meaning of words with multiple meanings. Simulations show that the model can reach up to 78% of word-referent association accuracy in ambiguous situations and approximates well the learning rates of humans as reported by three different authors in five Cross-Situational Word Learning experiments, also displaying similar learning patterns in the different learning conditions."
  authors: 
    - name: Hansenclever Bassani
    - name: Aluizio Araujo
  venue: Neural Networks
  links: 
    - name: PDF
      url: https://www.sciencedirect.com/science/article/pii/S0893608019301571

- title: "Dynamic topology and relevance learning SOM-based algorithm for image clustering tasks"
  year: 2019
  image: uvoc.png
  abstract: "In this paper, the task of unsupervised visual object categorization (UVOC) is addressed. We utilize a variant of Self-organizing Map (SOM) to cluster images in two different scenarios: disjoint (images from Caltech256) and non-disjoint (images from MSRC2) sets. First, we ran several tests to evaluate different image representation techniques: features obtained by a deep convolutional network were compared with those obtained by handcrafted methods, such as SIFT combined with a set of interest point detectors. As expected, we found that deep convolutional network features significantly outperformed its handcrafted counterparts. After choosing the best image representation technique, we compared the state-of-the-art image clustering algorithms with a SOM-based subspace clustering method that identifies automatically the relevant features in the high-dimensional image representations. The results have shown that our method achieves substantially lower clustering error than all competitors in several challenging testing settings."
  authors: 
    - name: Heitor Medeiros
    - name: Felipe Oliveira
    - name: Hansenclever Bassani
    - name: Aluizio Araujo
  venue: Computer Vision and Image Understanding
  links: 
    - name: PDF
      url: https://www.sciencedirect.com/science/article/pii/S107731421830451X

- title: "A Semi-Supervised Self-Organizing Map with Adaptive Local Thresholds"
  year: 2019
  image: alt-sssom.png
  abstract: "In the recent years, there is a growing interest in semi-supervised learning, since, in many learning tasks, there is a plentiful supply of unlabeled data, but insufﬁcient labeled ones. Hence, Semi-Supervised learning models can beneﬁt from both types of data to improve the obtained performance. Also, it is important to develop methods that are easy to parameterize in a way that is robust to the different characteristics of the data at hand. This article presents a new Self-Organizing Map (SOM) based method for clustering and classiﬁcation, called Adaptive Local Thresholds Semi-Supervised Self-Organizing Map (ALTSS-SOM). It can dynamically switch between two forms of learning at training time according to the availability of labels, as in previous models, and can automatically adjust itself to the local variance observed in each data cluster. The results show that the ALTSS-SOM surpass the performance of other semisupervised methods in terms of classiﬁcation, and other pure clustering methods when there are no labels available, being also less sensitive than previous methods to the parameters values."
  authors: 
    - name: Pedro Braga 
    - name: Hansenclever Bassani
  venue: International Joint Conference on Neural Networks (IJCNN)
  links: 
    - name: PDF
      url: 

- title: "A Semi-Supervised Self-Organizing Map for Clustering and Classification"
  year: 2018
  image: sssom.png
  abstract: "There has been an increasing interest in semi-supervised learning in the recent years because of the great number of datasets with a large number of unlabeled data but only a few labeled samples. Semi-supervised learning algorithms can work with both types of data, combining them to obtain better performance for both clustering and classification. Also, these datasets commonly have a high number of dimensions. This article presents a new semi-supervised method based on self-organizing maps (SOMs) for clustering and classification, called Semi-Supervised Self-Organizing Map (SS-SOM). The method can dynamically switch between supervised and unsupervised learning during the training according to the availability of the class labels for each pattern. Our results show that the SS-SOM outperforms other semi-supervised methods in conditions in which there is a low amount of labeled samples, also achieving good results when all samples are labeled."
  authors: 
    - name: Pedro Braga 
    - name: Hansenclever Bassani
  venue: International Joint Conference on Neural Networks (IJCNN)
  links: 
    - name: PDF
      url: https://ieeexplore.ieee.org/document/8489675

- title: "Incremental Semantic Mapping with Unsupervised On-line Learning"
  year: 2018
  image: OLARFDSSOM.jpg
  abstract: "This paper introduces an incremental semantic mapping approach, with on-line unsupervised learning, based on Self-Organizing Maps (SOM) for robotic agents. The method includes a mapping module, which incrementally creates a topological map of the environment, enriched with objects recognized around each topological node, and a module of places categorization, endowed with an incremental unsupervised learning SOM with on-line training. The proposed approach was tested in experiments with real-world data, in which it demonstrates promising capabilities of incremental acquisition of topological maps enriched with semantic information, and for clustering together similar places based on this information. The approach was also able to continue learning from newly visited environments without degrading the information previously learned."
  authors: 
    - name: Ygor C. N. Sousa 
    - name: Hansenclever Bassani
  venue: International Joint Conference on Neural Networks (IJCNN)
  links: 
    - name: PDF
      url: https://ieeexplore.ieee.org/abstract/document/8489430

- title: "Self-Organizing Maps with Variable Input Length for Motif Discovery and Word Segmentation"
  year: 2018
  image: vilmap.png
  abstract: "Time Series Motif Discovery (TSMD) is defined as searching for patterns that are previously unknown and appear with a given frequency in time series. Another problem strongly related with TSMD is Word Segmentation. This problem has received much attention from the community that studies early language acquisition in babies and toddlers. The development of biologically plausible models for word segmentation could greatly advance this field. Therefore, in this article, we propose the Variable Input Length Map (VILMAP) for Motif Discovery and Word Segmentation. The model is based on the Self-Organizing Maps and can identify Motifs with different lengths in time series. In our experiments, we show that VILMAP presents good results in finding Motifs in a standard Motif discovery dataset and can avoid catastrophic forgetting when trained with datasets with increasing values of input size. We also show that VILMAP achieves results similar or superior to other methods in the literature developed for the task of word segmentation."
  authors: 
    - name: Raphael C. Brito
    - name: Hansenclever Bassani
  venue: International Joint Conference on Neural Networks (IJCNN)
  links: 
    - name: PDF
      url: https://ieeexplore.ieee.org/abstract/document/8489430

- title: "MOEA/D with uniformly randomly adaptive weights"
  year: 2018
  image: moead.png
  abstract: "When working with decomposition-based algorithms, an appropriate set of weights might improve quality of the final solution. A set of uniformly distributed weights usually leads to well-distributed solutions on a Pareto front. However, there are two main difficulties with this approach. Firstly, it may fail depending on the problem geometry. Secondly, the population size becomes not flexible as the number of objectives increases. In this paper, we propose the MOEA/D with Uniformly Randomly Adaptive Weights (MOEA/D-URAW) which uses the Uniformly Randomly method as an approach to subproblems generation, allowing a flexible population size even when working with many objective problems. During the evolutionary process, MOEA/D-URAW adds and removes subproblems as a function of the sparsity level of the population. Moreover, instead of requiring assumptions about the Pareto front shape, our method adapts its weights to the shape of the problem during the evolutionary process. Experimental results using WFG41-48 problem classes, with different Pareto front shapes, shows that the present method presents better or equal results in 77.5% of the problems evaluated from 2 to 6 objectives when compared with state-of-the-art methods in the literature."
  authors: 
    - name: Lucas R. C. de Farias
    - name: Pedro Braga 
    - name: Hansenclever Bassani
    - name: Aluizio Araujo
  venue: Genetic and Evolutionary Computation Conference
  links: 
    - name: PDF
      url: https://dl.acm.org/citation.cfm?id=3205455.3205648

- title: "Dimension Selective Self-Organizing Maps With Time-Varying Structure for Subspace and Projected Clustering"
  year: 2014
  image: LARFDSSOM.png
  abstract: "Subspace clustering is the task of identifying clusters in subspaces of the input dimensions of a given dataset. Noisy data in certain attributes cause difficulties for traditional clustering algorithms, because the high discrepancies within them can make objects appear too different to be grouped in the same cluster. This requires methods specially designed for subspace clustering. This paper presents our second approach to subspace and projected clustering based on self-organizing maps (SOMs), which is a local adaptive receptive field dimension selective SOM. By introducing a time-variant topology, our method is an improvement in terms of clustering quality, computational cost, and parameterization. This enables the method to identify the correct number of clusters and their respective relevant dimensions, and thus it presents nearly perfect results in synthetic datasets and surpasses our previous method in most of the real-world datasets considered."
  authors: 
    - name: Hansenclever Bassani
    - name: Aluizio Araujo
  venue: IEEE Transactions on Neural Networks and Learning Systems
  links: 
    - name: PDF
      url: https://ieeexplore.ieee.org/document/6803941
